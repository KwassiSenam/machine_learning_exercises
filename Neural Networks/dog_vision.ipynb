{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-end Multil-class Dog Breed Classification\n",
        "\n",
        "This notebook builds an end-to-end multi-class image classifier using TensorFlow 2.x and TensorFlow Hub.\n",
        "\n",
        "## 1. Problem\n",
        "Identifying the breed of a dog given an image of a dog.\n",
        "\n",
        "## 2. Data\n",
        "The data we're using is from Kaggle's dog breed identification competition.\n",
        "https://www.kaggle.com/c/dog-breed-identification/data\n",
        "\n",
        "## 3. Evaluation\n",
        "The evaluation is a file with prediction probabilities for each dog breed of each test image.\n",
        "https://www.kaggle.com/c/dog-breed-identification/overview/evaluation\n",
        "\n",
        "## 4. Features\n",
        "Some information about the data:\n",
        "* We're dealing with images (unstructured data) so it's probably best we use deep learning/transfer learning.\n",
        "* There are 120 breeds of dogs (this means there are 120 different classes).\n",
        "* There are around 10,000+ images in the training set (these images have labels).\n",
        "* There are around 10,000+ images in the test set (these images have no labels, because we'll want to predict them)."
      ],
      "metadata": {
        "id": "Eo_R0Gd50jCN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFdN9e5hOb5h"
      },
      "outputs": [],
      "source": [
        "!unzip \"drive/My Drive/Dog Vision/dog-breed-identification.zip\" -d \"drive/My Drive/Dog Vision/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get our workspace ready"
      ],
      "metadata": {
        "id": "9dhGLyGT2vU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow and TensorFlow Hub into Colab\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub \n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"TF Hub version:\", hub.__version__)\n",
        "\n",
        "# Check for GPU availability\n",
        "print(\"GPU\", \"available (YESSSS!!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"
      ],
      "metadata": {
        "id": "2ZnAngKU2uOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting our data ready"
      ],
      "metadata": {
        "id": "LdEWLf8_48do"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we load labels.csv which contains all of the image ID's and their associated dog breed."
      ],
      "metadata": {
        "id": "OxfZHw7__r-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkout the labels of our data\n",
        "import pandas as pd\n",
        "labels = pd.read_csv(\"drive/My Drive/Dog Vision/labels.csv\")\n",
        "\n",
        "labels.head()"
      ],
      "metadata": {
        "id": "u2d90LQV7saP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.describe()"
      ],
      "metadata": {
        "id": "CyLS-R8J8G_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[\"breed\"].value_counts().plot.bar(figsize=(20, 10))"
      ],
      "metadata": {
        "id": "0NR5gXhw73II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[\"breed\"].value_counts().median()"
      ],
      "metadata": {
        "id": "RAMr9VZw8huH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c'est bien parce que Google recommande d'avoir 10 annotations au minimum par classe pour avoir un bon mod√®le."
      ],
      "metadata": {
        "id": "XOJIVENj9eGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(\"drive/My Drive/Dog Vision/train/001513dfcb2ffafc82cccf4d8bbaba97.jpg\")"
      ],
      "metadata": {
        "id": "1mgbcWz18uEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting images and their categorical labels\n",
        "\n",
        "#### Let's get a list of all of our image file pathnames."
      ],
      "metadata": {
        "id": "LfFUDgU_-DgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pathnames from image ID's\n",
        "filenames = [\"drive/My Drive/Dog Vision/train/\" + fname + \".jpg\" for fname in labels[\"id\"]]\n",
        "\n",
        "# Check the first 5\n",
        "filenames[:5]"
      ],
      "metadata": {
        "id": "cO0c46Dm9sBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check whether number of filenames matches number of our training files \n",
        "import os\n",
        "if len(os.listdir(\"drive/My Drive/Dog Vision/train/\")) == len(filenames):\n",
        "  print(\"Filenames match actual amount of files!!! Proceed.\")\n",
        "else:\n",
        "  print(\"Filenames do no match actual amount of files, check the target directory.\")"
      ],
      "metadata": {
        "id": "efFSjdk9-ZYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "labels = labels[\"breed\"].to_numpy() \n",
        "\n",
        "labels"
      ],
      "metadata": {
        "id": "jmDu5pSH--zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "id": "uLDSfCCQAKEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### checking for missing values in the train dataset"
      ],
      "metadata": {
        "id": "Ad8kKsN3A_0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see if number of labels matches the number of filenames\n",
        "if len(labels) == len(filenames):\n",
        "  print(\"Number of labels matches number of filenames!\")\n",
        "else:\n",
        "  print(\"Number of labels does not match number of filenames, check data directories!\")"
      ],
      "metadata": {
        "id": "bpZUHcyRAORg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, here we should have the same amount of images and labels."
      ],
      "metadata": {
        "id": "imVBmh7LCAQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Converting into numbers"
      ],
      "metadata": {
        "id": "wR0NswVrAw5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the unique label values\n",
        "unique_breeds = np.unique(labels)\n",
        "len(unique_breeds)"
      ],
      "metadata": {
        "id": "-hp5SwyHAg6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are working with images of 120 different breeds of dogs."
      ],
      "metadata": {
        "id": "ImCaHbyMCNpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a single label into an array of booleans\n",
        "print(labels[0])\n",
        "labels[0] == unique_breeds"
      ],
      "metadata": {
        "id": "nt9Q06OKBjXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[5] == unique_breeds"
      ],
      "metadata": {
        "id": "Im5_oC_kCos1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn every label into a boolean array\n",
        "boolean_labels = [label == np.array(unique_breeds) for label in labels]\n",
        "boolean_labels[:2]"
      ],
      "metadata": {
        "id": "MBrwK4Q-CvJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Turning a boolean array into integers\n",
        "print(labels[0]) # original label\n",
        "print(np.where(unique_breeds == labels[0])[0][0]) # index where label occurs\n",
        "print(boolean_labels[0].argmax()) # index where label occurs in boolean array\n",
        "print(boolean_labels[0].astype(int)) # there will be a 1 where the sample label occurs"
      ],
      "metadata": {
        "id": "PcIgXIxYDFSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating our own validation set"
      ],
      "metadata": {
        "id": "oRA_3Dq1EOZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation set is a split of the data we can test our model on before making final predicitons on the test set"
      ],
      "metadata": {
        "id": "VbQkldRtEVH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup X & y variables\n",
        "X = filenames\n",
        "y = boolean_labels"
      ],
      "metadata": {
        "id": "Fd9d36fkDd8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start experimenting with 1000 and increase it as we need."
      ],
      "metadata": {
        "id": "nJtsZtHPFNSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of images to use for experimenting\n",
        "NUM_IMAGES = 1000 #@param {type:\"slider\", min:1000, max:10000, step:1000}\n",
        "NUM_IMAGES"
      ],
      "metadata": {
        "id": "4VaeeeOQFH6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split them into training and validation using NUM_IMAGES \n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n",
        "                                                  y[:NUM_IMAGES], \n",
        "                                                  test_size=0.2,\n",
        "                                                  random_state=30)\n",
        "\n",
        "len(X_train), len(y_train), len(X_val), len(y_val)"
      ],
      "metadata": {
        "id": "71g7Qn7eFrt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the training data (image file paths and labels)\n",
        "X_train[:5], y_train[:2]"
      ],
      "metadata": {
        "id": "2Kc2al6LGHci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing images (turning images into Tensors)"
      ],
      "metadata": {
        "id": "sBlsXoFIGn06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensors = numerical representations"
      ],
      "metadata": {
        "id": "qx2ZFxhYGuey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To preprocess our images into Tensors we're going to write a function which does a few things:\n",
        "\n",
        "* Takes an image filename as input.\n",
        "* Uses TensorFlow to read the file and save it to a variable(image).\n",
        "* Turn our image(variable) into Tensors.\n",
        "* Normalize our image(convert color channel values from 0-225 values to 0-1 values.\n",
        "* Resize the image to be of shape (224, 224).\n",
        "* Return the modified image."
      ],
      "metadata": {
        "id": "5CI-09b6G9ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert image to NumPy array\n",
        "from matplotlib.pyplot import imread\n",
        "image = imread(filenames[3]) # read in an image\n",
        "image.shape # height, width, colour"
      ],
      "metadata": {
        "id": "_f49tFhJGZHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image size\n",
        "IMG_SIZE = 224\n",
        "\n",
        "def process_image(image_path):\n",
        "  \"\"\"\n",
        "  Takes an image file path and turns it into a Tensor.\n",
        "  \"\"\"\n",
        "  # Read in image file\n",
        "  image = tf.io.read_file(image_path)\n",
        "  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  # Convert the colour channel values from 0-225 values to 0-1 values\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  # Resize the image to our desired size (224, 244)\n",
        "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
        "\n",
        "  return image"
      ],
      "metadata": {
        "id": "GXuaNfqFHQK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating data batches"
      ],
      "metadata": {
        "id": "oxZZbBA0LB8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to use TensorFlow effectively, we need our data in the form of Tensor tuples which look like this: (image, label)"
      ],
      "metadata": {
        "id": "xAhtQMleMj6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function that returns a tuple (image, label)\n",
        "def get_image_label(image_path, label):\n",
        "  \"\"\"\n",
        "  Takes an image file path name and the associated label,\n",
        "  processes the image and returns a tuple of (image, label).\n",
        "  \"\"\"\n",
        "  image = process_image(image_path)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "QSZgSAFHLBTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(process_image(X[42]), tf.constant(y[42]))"
      ],
      "metadata": {
        "id": "IW098xroNUQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the batch size, 32 is a good default\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create a function to turn data into batches\n",
        "def create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
        "  \"\"\"\n",
        "  Creates batches of data out of image (x) and label (y) pairs.\n",
        "  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n",
        "  Also accepts test data as input (no labels).\n",
        "  \"\"\"\n",
        "  # If the data is a test dataset, we probably don't have labels\n",
        "  if test_data:\n",
        "    print(\"Creating test data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n",
        "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "  \n",
        "  # If the data if a valid dataset, we don't need to shuffle it\n",
        "  elif valid_data:\n",
        "    print(\"Creating validation data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
        "                                               tf.constant(y))) # labels\n",
        "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  else:\n",
        "    # If the data is a training dataset, we shuffle it\n",
        "    print(\"Creating training data batches...\")\n",
        "    # Turn filepaths and labels into Tensors\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
        "                                              tf.constant(y))) # labels\n",
        "    \n",
        "    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n",
        "    data = data.shuffle(buffer_size=len(x))\n",
        "\n",
        "    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n",
        "    data = data.map(get_image_label)\n",
        "\n",
        "    # Turn the data into batches\n",
        "    data_batch = data.batch(BATCH_SIZE)\n",
        "  return data_batch"
      ],
      "metadata": {
        "id": "6UULx9SlMnww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation data batches\n",
        "train_data = create_data_batches(X_train, y_train)\n",
        "val_data = create_data_batches(X_val, y_val, valid_data=True)"
      ],
      "metadata": {
        "id": "Q_nPthv8MzV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the different attributes of our data batches\n",
        "train_data.element_spec, val_data.element_spec"
      ],
      "metadata": {
        "id": "BIzcZVo7M6uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing data batches"
      ],
      "metadata": {
        "id": "aR_O3xkTSBNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a function for viewing images in a data batch\n",
        "def show_15_images(images, labels):\n",
        "  \"\"\"\n",
        "  Displays 15 images from a data batch.\n",
        "  \"\"\"\n",
        "  # Setup the figure\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  # Loop through 15 for displaying 15 images\n",
        "  for i in range(15):\n",
        "    # Create subplots (5 rows, 3 columns)\n",
        "    ax = plt.subplot(5, 3, i+1)\n",
        "    # Display an image\n",
        "    plt.imshow(images[i])\n",
        "    # Add the image label as the title\n",
        "    plt.title(unique_breeds[labels[i].argmax()])\n",
        "    # Turn gird lines off\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "em6tElvVRveo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "RLuE8D2xTbRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training images from the training data batch\n",
        "train_images, train_labels = next(train_data.as_numpy_iterator()) #unbatching\n",
        "train_images"
      ],
      "metadata": {
        "id": "syHfIW_zSkIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_15_images(train_images, train_labels)"
      ],
      "metadata": {
        "id": "8FH9ujNHTf5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize validation images from the validation data batch\n",
        "val_images, val_labels = next(val_data.as_numpy_iterator())\n",
        "show_15_images(val_images, val_labels)"
      ],
      "metadata": {
        "id": "0VnexwvsUpd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and training a model"
      ],
      "metadata": {
        "id": "DXfWENwvU5yH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Building a model"
      ],
      "metadata": {
        "id": "qT9nuR_sV9l9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup input shape to the model\n",
        "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n",
        "\n",
        "# Setup output shape of the model\n",
        "OUTPUT_SHAPE = len(unique_breeds) # number of unique labels\n",
        "\n",
        "# Setup model URL from TensorFlow Hub\n",
        "MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\""
      ],
      "metadata": {
        "id": "t2WBypKcUwAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We build a model in TensorFlow using the Keras API.\n",
        "\n",
        "let's create a function which:\n",
        "\n",
        "* Takes the input shape, output shape and the model we've chosen's URL as parameters.\n",
        "* Defines the layers in a Keras model in a sequential fashion (do this first, then this, then that).\n",
        "* Compiles the model (says how it should be evaluated and improved).\n",
        "* Builds the model (tells it what kind of input shape it'll be getting).\n",
        "* Returns the model."
      ],
      "metadata": {
        "id": "d11I7XejbbQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function which builds a Keras model\n",
        "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n",
        "  print(\"Building model with:\", MODEL_URL)\n",
        "\n",
        "  # Setup the model layers\n",
        "  model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n",
        "    tf.keras.layers.Dense(units=OUTPUT_SHAPE, \n",
        "                          activation=\"softmax\") # Layer 2 (output layer)\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)\n",
        "      optimizer=tf.keras.optimizers.Adam(), # A friend telling our model how to improve its guesses\n",
        "      metrics=[\"accuracy\"] # We'd like this to go up\n",
        "  )\n",
        "\n",
        "  # Build the model\n",
        "  model.build(INPUT_SHAPE) # Let the model know what kind of inputs it'll be getting\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "ZW4dJ3J6arRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model and check its details\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "4EP2us3xdI4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Creating callbacks"
      ],
      "metadata": {
        "id": "karS8RMTcCJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks are helper functions a model can use during training to do things such as save a models progress, check a models progress or stop training early if a model stops improving.\n",
        "\n",
        "We will use a TensorBoard callback and an Early Stopping callback."
      ],
      "metadata": {
        "id": "n2-7ufqecBJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### TensorBoard Callback"
      ],
      "metadata": {
        "id": "TYup7-6jcstM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It tracks our model progress."
      ],
      "metadata": {
        "id": "Dsb0vnw--Vvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "0QfXsI7FbJuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "# Create a function to build a TensorBoard callback\n",
        "def create_tensorboard_callback():\n",
        "  # Create a log directory for storing TensorBoard logs\n",
        "  logdir = os.path.join(\"drive/My Drive/Dog Vision/logs\",\n",
        "                        # Make it so the logs get tracked whenever we run an experiment\n",
        "                        datetime.datetime.now().strftime(\"%d%m%Y-%H%M%S\"))\n",
        "  return tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "metadata": {
        "id": "m6EYg2z0cyva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Early Stopping Callback"
      ],
      "metadata": {
        "id": "hoaGoAcUc1Ya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It helps prevent overfitting by stopping a model when a certain evaluation metric stops improving."
      ],
      "metadata": {
        "id": "vaEbQFuU-cEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create early stopping (once our model stops improving, stop training)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                  patience=3) # stops after 3 rounds of no improvements"
      ],
      "metadata": {
        "id": "Xf2HnD1Jc4y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Training a model (on a subset of data)"
      ],
      "metadata": {
        "id": "MqnyfKm1c8Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 100 #@param {type:\"slider\", min:10, max:100, step:10}"
      ],
      "metadata": {
        "id": "OhQ6Z2JmdBza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a function to train and return a trained model\n",
        "def train_model():\n",
        "  \"\"\"\n",
        "  Trains a given model and returns the trained version.\n",
        "  \"\"\"\n",
        "  # Create a model\n",
        "  model = create_model()\n",
        "\n",
        "  # Create new TensorBoard session everytime we train a model\n",
        "  tensorboard = create_tensorboard_callback()\n",
        "\n",
        "  # Fit the model to the data passing it the callbacks we created\n",
        "  model.fit(x=train_data,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            validation_data=val_data,\n",
        "            validation_freq=1, # check validation metrics every epoch\n",
        "            callbacks=[tensorboard, early_stopping])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "BOsdNzrREIiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the data\n",
        "model = train_model()"
      ],
      "metadata": {
        "id": "1iFRv4pnEYKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we've weak generalisation(overfitting) <=> train_accuracy very greater than val_accuracy"
      ],
      "metadata": {
        "id": "CgjZyKvUGi6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir drive/My\\ Drive/Data/logs"
      ],
      "metadata": {
        "id": "G30VBJkfEg7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making and evaluating predictions using the trained model"
      ],
      "metadata": {
        "id": "Iw0Asf5zEw93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation data (not used to train on)\n",
        "predictions = model.predict(val_data, verbose=1) # verbose shows us how long there is to go\n",
        "predictions"
      ],
      "metadata": {
        "id": "TGyNW9OJEwKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "id": "Velr7X2_Kkpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(predictions[2])"
      ],
      "metadata": {
        "id": "QflhA1HpK-QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "predictions = (prediction, probability)"
      ],
      "metadata": {
        "id": "WJGsbdWMKc96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First prediction\n",
        "print(predictions[0])\n",
        "print(f\"Max value (probability of prediction): {np.max(predictions[0])}\") # the max probability value predicted by the model\n",
        "print(f\"Sum: {np.sum(predictions[0])}\") # because we used softmax activation in our model, this will be close to 1\n",
        "print(f\"Max index: {np.argmax(predictions[0])}\") # the index of where the max value in predictions[0] occurs\n",
        "print(f\"Predicted label: {unique_breeds[np.argmax(predictions[0])]}\") # the predicted label"
      ],
      "metadata": {
        "id": "XwogDbeIFG7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_breeds[54]"
      ],
      "metadata": {
        "id": "btcJWhx-L2oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into their respective label (easier to understand)\n",
        "def get_pred_label(prediction_probabilities):\n",
        "  \"\"\"\n",
        "  Turns an array of prediction probabilities into a label.\n",
        "  \"\"\"\n",
        "  return unique_breeds[np.argmax(prediction_probabilities)]\n",
        "\n",
        "# Get a predicted label based on an array of prediction probabilities\n",
        "pred_label = get_pred_label(predictions[0])\n",
        "pred_label"
      ],
      "metadata": {
        "id": "0OQpzeFRFIzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to unbatch a batched dataset\n",
        "def unbatchify(data):\n",
        "  \"\"\"\n",
        "  Takes a batched dataset of (image, label) Tensors and returns separate arrays\n",
        "  of images and labels.\n",
        "  \"\"\"\n",
        "  images = []\n",
        "  labels = []\n",
        "  # Loop through unbatched data\n",
        "  for image, label in data.unbatch().as_numpy_iterator():\n",
        "    images.append(image)\n",
        "    labels.append(unique_breeds[np.argmax(label)])\n",
        "  return images, labels\n",
        "\n",
        "# Unbatchify the validation data\n",
        "val_images, val_labels = unbatchify(val_data)\n",
        "val_images[0], val_labels[0]"
      ],
      "metadata": {
        "id": "b9N-mZJVHUIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred(prediction_probabilities, labels, images, n=0):\n",
        "  \"\"\"\n",
        "  View the prediction, ground truth label and image for sample n.\n",
        "  \"\"\"\n",
        "  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n",
        "  \n",
        "  # Get the pred label\n",
        "  pred_label = get_pred_label(pred_prob)\n",
        "  \n",
        "  # Plot image & remove ticks\n",
        "  plt.imshow(image)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  # Change the color of the title depending on if the prediction is right or wrong\n",
        "  if pred_label == true_label:\n",
        "    color = \"green\"\n",
        "  else:\n",
        "    color = \"red\"\n",
        "\n",
        "  plt.title(\"{} {:2.0f}% ({})\".format(pred_label,\n",
        "                                      np.max(pred_prob)*100,\n",
        "                                      true_label),\n",
        "                                      color=color)"
      ],
      "metadata": {
        "id": "0bCr2Jo2HUwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View an example prediction, original image and truth label\n",
        "plot_pred(prediction_probabilities=predictions,\n",
        "          labels=val_labels,\n",
        "          images=val_images)"
      ],
      "metadata": {
        "id": "Nakq5TGzHYq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred_conf(prediction_probabilities, labels, n=0):\n",
        "  \"\"\"\n",
        "  Plots the top 10 highest prediction confidences along with\n",
        "  the truth label for sample n.\n",
        "  \"\"\"\n",
        "  pred_prob, true_label = prediction_probabilities[n], labels[n]\n",
        "\n",
        "  # Get the predicted label\n",
        "  pred_label = get_pred_label(pred_prob)\n",
        "\n",
        "  # Find the top 10 prediction confidence indexes\n",
        "  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n",
        "  # Find the top 10 prediction confidence values\n",
        "  top_10_pred_values = pred_prob[top_10_pred_indexes]\n",
        "  # Find the top 10 prediction labels\n",
        "  top_10_pred_labels = unique_breeds[top_10_pred_indexes]\n",
        "\n",
        "  # Setup plot\n",
        "  top_plot = plt.bar(np.arange(len(top_10_pred_labels)), \n",
        "                     top_10_pred_values, \n",
        "                     color=\"grey\")\n",
        "  plt.xticks(np.arange(len(top_10_pred_labels)),\n",
        "             labels=top_10_pred_labels,\n",
        "             rotation=\"vertical\")\n",
        "\n",
        "  # Change color of true label\n",
        "  if np.isin(true_label, top_10_pred_labels):\n",
        "    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n",
        "  else:\n",
        "    pass"
      ],
      "metadata": {
        "id": "nBFjHf_oHcJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred_conf(prediction_probabilities=predictions,\n",
        "               labels=val_labels,\n",
        "               n=9)"
      ],
      "metadata": {
        "id": "ZbbBX_QXHeDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check a few predictions and their different values\n",
        "i_multiplier = 0\n",
        "num_rows = 3\n",
        "num_cols = 2\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(5*2*num_cols, 5*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_pred(prediction_probabilities=predictions,\n",
        "            labels=val_labels,\n",
        "            images=val_images,\n",
        "            n=i+i_multiplier)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_pred_conf(prediction_probabilities=predictions,\n",
        "                labels=val_labels,\n",
        "                n=i+i_multiplier)\n",
        "plt.tight_layout(h_pad=1.0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tgvevjTqHgDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving and reloading a model"
      ],
      "metadata": {
        "id": "fKpQZCeXRsG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, suffix=None):\n",
        "  \"\"\"\n",
        "  Saves a given model in a models directory and appends a suffix (str)\n",
        "  for clarity and reuse.\n",
        "  \"\"\"\n",
        "  # Create model directory with current time\n",
        "  modeldir = os.path.join(\"drive/My Drive/Dog Vision/models\",\n",
        "                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n",
        "  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n",
        "  print(f\"Saving model to: {model_path}...\")\n",
        "  model.save(model_path)\n",
        "  return model_path"
      ],
      "metadata": {
        "id": "lY4FHhDLRrRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path):\n",
        "  \"\"\"\n",
        "  Loads a saved model from a specified path.\n",
        "  \"\"\"\n",
        "  print(f\"Loading saved model from: {model_path}\")\n",
        "  model = tf.keras.models.load_model(model_path,\n",
        "                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n",
        "  return model"
      ],
      "metadata": {
        "id": "vR4XG3FgR9mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save our model trained on 1000 images\n",
        "save_model(model, suffix=\"1000-images-Adam\")"
      ],
      "metadata": {
        "id": "tmO_Rg4KR_5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load our model trained on 1000 images\n",
        "model_1000_images = load_model('drive/My Drive/Dog Vision/models/20221001-20551664657753-1000-images-Adam.h5')"
      ],
      "metadata": {
        "id": "rlxN3apUSDi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the pre-saved model\n",
        "model.evaluate(val_data)"
      ],
      "metadata": {
        "id": "dqfqXsa7SFjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the loaded model\n",
        "model_1000_images.evaluate(val_data)"
      ],
      "metadata": {
        "id": "Mp44RO0ZSHvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training a model (on the full data)"
      ],
      "metadata": {
        "id": "ujnERLdbSKUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn full training data in a data batch\n",
        "full_data = create_data_batches(X, y)"
      ],
      "metadata": {
        "id": "j9VxCNAISJts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a new model for training on the full dataset\n",
        "full_model = create_model()"
      ],
      "metadata": {
        "id": "un8nLWzOWZ_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating callbacks\n",
        "\n",
        "# TensorBoard callback\n",
        "full_model_tensorboard = create_tensorboard_callback()\n",
        "\n",
        "# Early stopping callback\n",
        "full_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n",
        "                                                             patience=3)"
      ],
      "metadata": {
        "id": "2SsvCnZ9Wdhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir drive/My\\ Drive/Data/logs"
      ],
      "metadata": {
        "id": "sYMAcwbkWtiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the full model to the full training data\n",
        "full_model.fit(x=full_data,\n",
        "               epochs=NUM_EPOCHS,\n",
        "               callbacks=[full_model_tensorboard, \n",
        "                          full_model_early_stopping])"
      ],
      "metadata": {
        "id": "jsh4z5LNW0X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving and reloading the full model"
      ],
      "metadata": {
        "id": "IhJm_I_QW9dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model to file\n",
        "save_model(full_model, suffix=\"all-images-Adam\")"
      ],
      "metadata": {
        "id": "QD1EJ-qgW_qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the full model\n",
        "loaded_full_model = load_model('drive/My Drive/Dog Vision/models/20200131-03111580440309-all-images-Adam.h5')"
      ],
      "metadata": {
        "id": "2bnUR7OjXE4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making predictions on the test dataset"
      ],
      "metadata": {
        "id": "489qL8y4XIo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test image filenames (since we're using os.listdir(), these already have .jpg)\n",
        "test_path = \"drive/My Drive/Dog Vision/test/\"\n",
        "test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n",
        "\n",
        "test_filenames[:10]"
      ],
      "metadata": {
        "id": "BscvHzn1XKWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_filenames)"
      ],
      "metadata": {
        "id": "gD3NBNGfXQ7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create test data batch\n",
        "test_data = create_data_batches(test_filenames, test_data=True)"
      ],
      "metadata": {
        "id": "FGTLP-fvXSsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on test data batch using the loaded full model\n",
        "test_predictions = loaded_full_model.predict(test_data,\n",
        "                                             verbose=1)"
      ],
      "metadata": {
        "id": "f6_qeoMGXWhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the test predictions\n",
        "test_predictions[:10]"
      ],
      "metadata": {
        "id": "eOGuerXZXYyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making predictions on custom images"
      ],
      "metadata": {
        "id": "AvB2bD4PXfBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get custom image filepaths\n",
        "custom_path = \"drive/My Drive/Dog Vision/other_dogs/\"\n",
        "custom_image_paths = [custom_path + fname for fname in os.listdir(custom_path)]"
      ],
      "metadata": {
        "id": "j15-9xDFXefX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn custom image into batch (set to test data because there are no labels)\n",
        "custom_data = create_data_batches(custom_image_paths, test_data=True)"
      ],
      "metadata": {
        "id": "KF-u0nb8X8VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the custom data\n",
        "custom_preds = loaded_full_model.predict(custom_data)"
      ],
      "metadata": {
        "id": "g0c9MXSIYArl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get custom image prediction labels\n",
        "custom_pred_labels = [get_pred_label(custom_preds[i]) for i in range(len(custom_preds))]\n",
        "custom_pred_labels"
      ],
      "metadata": {
        "id": "CNog1h4_YHmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get custom images \n",
        "#our unbatchify() function won't work because there are no labels)\n",
        "custom_images = []\n",
        "# Loop through unbatched data\n",
        "for image in custom_data.unbatch().as_numpy_iterator():\n",
        "  custom_images.append(image)"
      ],
      "metadata": {
        "id": "mA7_IB1oYKVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check custom image predictions\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, image in enumerate(custom_images):\n",
        "  plt.subplot(1, 3, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.title(custom_pred_labels[i])\n",
        "  plt.imshow(image)"
      ],
      "metadata": {
        "id": "HDMbjD-dYdOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fBBjhzOqYNlN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}